~~Title: C Primer~~
~~CODE-c~~

==== Preface ====

//This is not a theoretical C language specifications document. It is a practical primer for the vast majority of real life cases of C usage that are relevant to EFL on todays common architectures. It covers application executables and shared library concepts and is written from a Linux/UNIX perspective where you would have your code running with an OS doing memory mappings and probably protection for you. It really is fundamentally not much different on Android, iOS, OSX or even Windows.//

//It won't cover esoteric details of "strange architectures". It pretty much covers C as a high level assembly language that is portable across a range of modern architectures.//

==== Your first program ====

Let's start with the traditional "Hello world" C application. This is about as simple as it gets for an application that does something you can see.

<code c hello.c>
#include <stdio.h>

int
main(int argc, char **argv)
{
   printf("Hello world!\n");
   return 0;
}
</code>

You would compile this on a command-line as follows:

  cc hello.c -o hello

Run the application with:

  ./hello

You should then see this output:

  Hello world!

So what has happened here? Let's first look at the code itself. The first line:

<code c>
#include <stdio.h>
</code>

This tells the compiler to literally include the **stdio.h** file into your application. The compiler will find this file in the standard locations to look for include files and literally "paste" it there where the include line is. This file provides some "standard I/O" features, such as ''printf()''.

The next thing is something every application will have - a ''main()'' function. This function must exist only once in the application because this is the function that is run //AS// the application. When this function exits, the application does.

<code c>
int
main(int argc, char **argv)
{
}
</code>

The ''main()'' function always returns an ''integer'' value, and is given 2 parameters on start. Those are an integer ''argc'' and then an array of strings. In C an array is generally just a pointer to the first element. A String is generally a pointer to a series of bytes (chars) which ends in a byte value of 0 to indicate the end of the string. We'll come back to this later, but as we don't use these, just ignore this for now.

The next thing that happens is for the code to call a function ''printf()'' with a string "Hello world!\n". Why the "\n" at the end? This is an "escape". A way of indicating a special character. In this case this is the //newline// character. Strings in C can contain some special characters like this, and "\" is used to begin the escaped string.

<code c>
printf("Hello world!\n");
</code>

Now finally we return from the main function with the value 0. The ''main()'' function of an application is special. It always returns an integer that indicates the "success" of the application. This is used by the shell executing the process to determine success. A return of ''0'' indicates the process ran successfully. Any other return value is an indicator of failure.

<code c>
return 0;
</code>

You will notice a few things. First lines starting with ''#'' are commands, but don't have a '';''. This is normal because these lines are processed by the pre-processor. All code in C goes through the C pre-processor and this basically generates more code for the compiler to actually deal with. Other lines that are not starting a function, ending it or defining control end every statement in C with a '';'' character. If you don't do this, the statement continues until a '';'' is found, even if it goes across multiple lines.

If we look at how the application is compiled, We execute the C compiler, give it 1 or more source files to compile and the with ''-o'' tell it what output file to produce (the executable)

  cc hello.c -o hello

Often ''cc'' will be replaced with things like ''gcc'' or maybe ''clang'' or whatever compiler you prefer. A compiler will run the source through the pre-processor and then convert your source code into a binary form that your CPU and Os can actually understand and run.

Now let's take a detour back to the machine that is running your very first C application.

==== The machine ====

Reality is that you are dealing with a machine. A real modern piece of hardware. Not abstract. It's real. Most machines are fairly similar these days, of course with their variations on personality, size etc.

All machines have at least a single processor to execute a series of instructions. If you write an application (a common case) this is the model you will see right in front of you. An application begins by executing a list of instructions at the CPU level.

The C compiler takes the C code source files you write and converts them into "machine code" (which is really just a series of numbers that end up stored in memory, and these numbers have meanings like "0" is "do nothing", "1" is "add the next 2 numbers together and store the result" etc.). Somewhere these numbers are placed in memory by the operating system when the executable is loaded, and the CPU is instructed to begin executing them. What these numbers mean is dependent on your CPU type.

An example:

^Memory location ^Value in hexadecimal ^Instruction meaning ^
|0               |e1510000             |cmp r1, r0          |
|4               |e280001a             |add r0, r0, #26     |


CPUs will do arithmetic, logic operations, change what it is they execute, and read from or write to memory to deal with data. In the end, everything to a CPU is effectively a number, somewhere to store it to or load it from and some operation you do to it.

To computers, numbers are a string of "bits". A bit can be on or off. Just like you may be used to numbers, with each digit having 10 values (0 through to 9), A computer sees numbers more simply. It is 0, or it is 1. Just like you can have a bigger number by adding a digit (1 digit can encode 10 values, 2 digits can encode 100 values, 3 can encode 1000 values etc.), So too with the binary (0 or 1) numbering system computers use. Every binary digit you add doubles the number of values you can deal with. For convenience we often use Hexadecimal as a way of writing numbers because it aligns nicely with the bits used in binary. Hexadecimal uses 16 values per digit, with 0 through to 9, then a through to f being digits.

^Binary           ^Hexadecimal ^Decimal ^
|101              |d           |14      |
|00101101         |2d          |46      |
|1111001101010001 |f351        |62289   |

Numbers to a computer normally come in sizes that indicate how many bits they use. The sizes that really matter are:

^Common term       ^C type    ^Number of bits ^Max unsigned                  ^
|Byte              |char      |8              |255                           |
|Word              |short     |16             |65535                         |
|Integer           |int       |32             |~4 billion                    |
|Long Integer      |long      |32 / 64        |~4 billion / ~18 qunitillion  |
|Long Long Integer |long long |64             |~18 qunitillion               |
|Float             |float     |32             |3.402823466 e+38              |
|Double Float      |double    |64             |1.7976931348623158 e+308      |
|Pointer           |* **X**   |32 / 64        |~4 billion / ~18 qunitillion  |

The sizes here are the **COMMON SIZES** found across real life architectures today. //(This does gloss over some corner cases such as on x86 systems, doubles can be 80 bits whilst they are inside a register, etc.)//

Pointers are also just integers. Either 32 or 64 bits. They refer to a location in memory as a multiple of bytes. Floats and doubles can encode numbers with "a decimal place". Like  3.14159. Thus both floats and doubles consist of a mantissa and exponent. The mantissa determines the digits of the number and the exponent determines where the decimal place should go.

When we want signed numbers, we center our ranges AROUND 0. So bytes (chars) can go from -128 to 127, shorts from -32768 to 32767, and so on. By default all of the types are signed (except pointers) UNLESS you put an "unsigned" in front of them. You can also place "signed" in front to explicitly say you want the type to be signed. //A catch - on ARM systems chars often are unsigned by default//. Also be aware that it is common on 64 bit systems to have long integers be 64 bit, and on 32 bit they switch to being 32 bits. Windows is the exception here and long integers will remain 32 bit (we are skipping windows 16 bit coding here).

Pointers follow the instruction set mode. For 32 bit architectures pointers are 32 bits in size, and are bits in size on 64 bit architectures. Standard ARM systems are 32 bit, except for very new 64 bit ARM systems. On x86, 64 bit has been around for a while, and so you will commonly see both. This is the same for PowerPC and MIPS as well.

Memory to a machine is just a big "spreadsheet" of numbers. Imagine it as a spreadsheet with only 1 column and a lot of rows. Every cell can store 8 bits (a byte). If you "merge" rows (2, 4, 8) you can store more values as above. But when you merge rows, the next row number doesn't change. You also could still address the "parts" of the merged cell as bytes or smaller units. In the end pointers are nothing more than a number saying "go to memory row 2943298 and get me the integer (4 bytes) located there" (if it was a pointer to an integer). The pointer itself just stores the PLACE in memory where you find the data. The data itself is what you get when you de-reference a pointer.

This level of indirection can nest. You can have a pointer to pointers, so de-reference a pointer to pointers to get the place in memory where the actual data is then de-reference that again to get the data itself. Follow the chain of pointers if you want values. Since pointers are numbers, you can do math on them like any other. You can advance through memory just by adding 1, 2, 4 or 8 to your pointer to point to the "next thing along" for example, which is how arrays work. 

In general machines like to store these numbers in memory at a place that is aligned to their size. That means that bytes (chars) can be stored anywhere as the smallest unit when addressing memory is a byte (in general). Shorts want to be aligned to 16 bits - that means 2 bytes (chars), so you should (ideally) never find a short at an ODD byte in memory. Integers want to be stored on 4 byte boundaries, Long integers may align to either 4 or 8 bytes depending, and long long integers on 8 byte boundaries. Floats would align to 4 bytes, doubles to 8 bytes, and pointers to either 4 or 8 bytes depending on size. Some architectures such as x86, don't care if you align things, and will "fix things up for you" transparently. But others (most actually) care and will refuse to access data if it is nor aligned correctly.

So keep this in mind as a general rule - your data must be aligned. The C compiler will do most of this for you, until you start doing "fun" things with pointers.

Note that in addition to memory, CPUs will have "temporary local registers" that are directly inside the CPU. They do not have addresses. The compiler will use them as temporary scratch space to store data from memory so the CPU can work on it. Different CPU types have different numbers and naming of such registers. ARM CPUs tend to have more registers than x86 for example.

==== Variables ====

C provides you with a handy "abstraction" to store data in memory. These are normally variables. When you first see some C code, you likely see some variables and these are stored on the stack. This is a special place in memory for such temporary variables and data. It grows and shrinks as needed and has a specific order to store data.

Other data is likely on the "heap" and you will explicitly ask it to be there. The heap is basically a "big mess of data" where you likely have more permanent data or the larger bits of data. C provides some basic methods to ask for this storage, where the stack allocation space is generally implicit when you call a function.

Variables will live within this memory, and normally the C compiler will deal with alignment (especially the stack). You simply say "I want a variable called "bob", that is of the type "integer". The type of a variable tells the compiler how much memory it should use. The name is how to refer to it in your code.

<code c>
int bob;
</code>

You can even tell the compiler to make sure it has an initial value. If you don't it's value may be random garbage that was there before in memory.

<code c>
int bob = 42;
</code>

Once you have declared a variable, you can now use it. You can group values together in repeating sequences using //arrays// or in mixed groups called //structs// that contain a sequence of variables structured as indicated. Order is important and is maintained in memory. You can at times take advantage of this ordering for doing things like "inheritance". Arrays also have strict ordering in memory, so you can later on use pointers and simple arithmetic to walk up and down an array to access data, which is very handy on many occasions.

<code c>
int bobs[100];
double things[200];
</code>

<code c>
struct mydata
  {
     int count;
     double items[100];
  };

struct mydata bob;
</code>

Structs (structured data) are very important and allow C to become rather complex and powerful when it comes to data storage, and don't forget you can embed structs inside structs, have arrays of structs, structs with arrays and use pointers to indirect from one struct to another, arrays of pointers to structs and so on.

==== Functions ====

A function is a basic unit of execution. Conceptually a function hides an implementation of how to do something and exposes this as a higher level command. "Go make me a sandwich, using butter, cheese and ham" could be seen as calling the "make me a sandwich" function, with the input parameters (or arguments) being butter, cheese and ham, and the function returns a sandwich (for example). In C we might express this as follows:

<code c>
struct sandwich
  {
    struct bread_slice top;
    struct bread_slice bottom;
    enum filling *fillings;
    int num_fillings;
  };

enum filling
  {
    FILLING_HAM,
    FILLING_CHEESE,
    FILLING_BUTTER
  };

struct sandwich *
make_sandwich(enum filling *fillings, int num_fillings)
  {
    struct sandwich *sandwich;
    int i;
    
    sandwich = malloc(sizeof(struct sandwich));
    if (!sandwich) return NULL;
    sandwich->fillings = malloc(sizeof(enum filling) * num_fillings);
    if (!sandwich->fillings)
      {
        free(sandwich);
        return NULL;
      }
    for (i = 0; i < num_fillings; i++)
      sandwich->fillings[i] = fillings[i];
    sandwich->num_fillings = num_fillings;
    return sandwich;
  }
</code>

I may call the function as follows:

<code c>
struct sandwich *sandwich;
struct filling my_fillings[3] = {FILLING_HAM, CHEESE, BUTTER};

sandwich = make_sandwich(my_fillings, 3);
</code>

==== Types ====
==== Arithmetic ====
==== Logic ====
==== Loops ====
----
==== Memory ====
==== Libraries ====
==== API calls ====
==== System calls ====
----
==== Alignment ====
==== Endianess ====
==== Function pointers ====
==== Callbacks ====
==== Threads ====

=== Also See ===

Now you have read our less-than-perfect primer on C for those wanting to get into developing on EFL or using it from the C APIs we have, you may also want to look at the following list of pages and pick up some more information or fill in the gaps we do not cover here.

  * [[http://www.cprogramming.com/tutorial/c-tutorial.html|C tutorial]]

----

~~DISCUSSIONS~~